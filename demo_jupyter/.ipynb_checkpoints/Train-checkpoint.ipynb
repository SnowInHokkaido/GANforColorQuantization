{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import Generative_Network\n",
    "import Discriminative_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "palettepath = 'D:\\\\PythonScript\\\\Comp5422\\\\github\\\\GANforColorQuantization\\\\demo_jupyter\\\\lab_palette.npy'\n",
    "\n",
    "quantized_lab = np.load(palettepath)\n",
    "\n",
    "net_path = 'D:\\\\PythonScript\\\\Dissertation\\\\Gatys Implemention\\\\Style_transfer_Saliency_loss\\\\imagenet-vgg-verydeep-19.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g_network(image, quantized_lab, reuse=False,):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    '''\n",
    "    \n",
    "    在重复使用的时候, 一定要在代码中强调 scope.reuse_variables(), 否则系统将会报错, 以为你只是单纯的不小心重复使用到了一个变量\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    prob = Generative_Network.net(image)\n",
    "    fake_image = Generative_Network.mapping(prob, quantized_lab)\n",
    "    return fake_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def d_network(image, weights, reuse = False):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()  \n",
    "    \n",
    "    prob, logits = Discriminative_Network.discriminator(image, weights)\n",
    "    \n",
    "    return prob, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Testing Data\n",
    "\n",
    "'''\n",
    "\n",
    "img_path = 'C:\\\\Users\\\\Orion_Peng\\\\Pictures\\\\Saved Pictures\\\\dog.jpg'\n",
    "img = scipy.misc.imread(img_path, mode = 'RGB')\n",
    "img = scipy.misc.imresize(img, (256, 256)) # Image Resizing\n",
    "weights, mean_pixel = Discriminative_Network.load_net(net_path)\n",
    "img = Discriminative_Network.preprocess(img, mean_pixel)\n",
    "input_img = np.array([img]) # Add to batch\n",
    "\n",
    "input_img.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [1, 256, 256, 3])\n",
    "\n",
    "G_sample = g_network(X, quantized_lab)\n",
    "\n",
    "D_real, D_logit_real = d_network(X, weights)\n",
    "\n",
    "D_fake, D_logit_fake = d_network(G_sample, weights)\n",
    "\n",
    "with tf.name_scope('D_loss'):\n",
    "    D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
    "    D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
    "    D_loss = D_loss_real + D_loss_fake\n",
    "    \n",
    "with tf.name_scope('G_loss'):\n",
    "    G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))\n",
    "    \n",
    "tvar = tf.trainable_variables()\n",
    "dvar = [var for var in tvar if 'discriminator' in var.name] # Find variable in DN\n",
    "gvar = [var for var in tvar if 'generator' in var.name] # Find variable in GB\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    d_train = tf.train.AdamOptimizer().minimize(D_loss, var_list=dvar)\n",
    "    g_train = tf.train.AdamOptimizer().minimize(G_loss, var_list=gvar)\n",
    "    \n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(100):\n",
    "        if i % 10 == 0:\n",
    "            samples = sess.run(G_sample, feed_dict={X: input_img})\n",
    "\n",
    "    \n",
    "        _, D_loss_curr = sess.run([d_train, D_loss], feed_dict={X: input_img})\n",
    "        _, G_loss_curr = sess.run([g_train, G_loss], feed_dict={X: input_img})\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(D_loss_curr, G_loss_curr)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
