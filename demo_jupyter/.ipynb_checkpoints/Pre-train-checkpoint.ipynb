{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VGG19_LAYERS=(\n",
    "    'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
    "\n",
    "    'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    "\n",
    "    'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
    "    'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    "\n",
    "    'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
    "    'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    "\n",
    "    'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
    "    'relu5_3', 'conv5_4', 'relu5_4'\n",
    ")\n",
    "\n",
    "def load_net(data_path):\n",
    "    data = scipy.io.loadmat(data_path)\n",
    "    mean = data['normalization'][0][0][0]\n",
    "    mean_pixel = np.mean(mean, axis=(0,1))\n",
    "    weights = data['layers'][0]\n",
    "    return weights, mean_pixel \n",
    "\n",
    "def _conv_layer(input, weights, bias):\n",
    "    conv = tf.nn.conv2d(input, tf.constant(weights), strides=(1, 1, 1, 1),\n",
    "            padding='SAME')\n",
    "    return tf.nn.bias_add(conv, bias)\n",
    "\n",
    "def _pool_layer(input):\n",
    "    return tf.nn.max_pool(input, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1),\n",
    "            padding='SAME')\n",
    "\n",
    "def preprocess(image, mean_pixel):\n",
    "    return image - mean_pixel\n",
    "\n",
    "def unprocess(image, mean_pixel):\n",
    "    return image + mean_pixel\n",
    "\n",
    "def net_preloaded(input_image, weights):\n",
    "    net = {}\n",
    "    current = input_image\n",
    "\n",
    "    for i, name in enumerate(VGG19_LAYERS):\n",
    "        kind = name[:4]\n",
    "        if kind == 'conv':\n",
    "            kernels, bias =  weights[i][0][0][0][0] \n",
    "\n",
    "            # tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "            kernels = np.transpose(kernels, (1, 0, 2, 3))\n",
    "            bias = bias.reshape(-1)\n",
    "\n",
    "            current = _conv_layer(current, kernels, bias)\n",
    "        elif kind == 'relu':\n",
    "            current = tf.nn.relu(current)\n",
    "        elif kind == 'pool':\n",
    "            current = _pool_layer(current)\n",
    "        net[name] = current\n",
    "\n",
    "    assert len(net) == len(VGG19_LAYERS)\n",
    "    return net\n",
    "\n",
    "def batch_norm(input):\n",
    "    '''\n",
    "    Batch Normalization \n",
    "    '''\n",
    "    '''\n",
    "        channels = input.get_shape()[3]\n",
    "        offset = tf.get_variable(\"offset\", [channels], dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "        scale = tf.get_variable(\"scale\", [channels], dtype=tf.float32, initializer=tf.random_normal_initializer(1.0, 0.02))\n",
    "        mean, variance = tf.nn.moments(input, axes=[0, 1, 2], keep_dims=False)\n",
    "    '''\n",
    "    epsilon = 1e-3\n",
    "    batch_mean,batch_var=tf.nn.moments(input,[0])\n",
    "    normalized=tf.nn.batch_normalization(input,mean=batch_mean,variance=batch_var,offset=None,scale=None,variance_epsilon=epsilon)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'D:\\\\PythonScript\\\\Dissertation\\\\Gatys Implemention\\\\Style_transfer_Saliency_loss\\\\imagenet-vgg-verydeep-19.mat'\n",
    "weights, mean_pixel = load_net(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 123.68 ,  116.779,  103.939])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 512, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = scipy.misc.imread('C:\\\\Users\\\\Orion_Peng\\\\Pictures\\\\animal_1_resize.jpg')\n",
    "img = preprocess(img, mean_pixel)\n",
    "img = np.array([img]).astype(np.float32)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1_1': <tf.Tensor 'BiasAdd:0' shape=(1, 512, 512, 64) dtype=float32>,\n",
       " 'conv1_2': <tf.Tensor 'BiasAdd_1:0' shape=(1, 512, 512, 64) dtype=float32>,\n",
       " 'conv2_1': <tf.Tensor 'BiasAdd_2:0' shape=(1, 256, 256, 128) dtype=float32>,\n",
       " 'conv2_2': <tf.Tensor 'BiasAdd_3:0' shape=(1, 256, 256, 128) dtype=float32>,\n",
       " 'conv3_1': <tf.Tensor 'BiasAdd_4:0' shape=(1, 128, 128, 256) dtype=float32>,\n",
       " 'conv3_2': <tf.Tensor 'BiasAdd_5:0' shape=(1, 128, 128, 256) dtype=float32>,\n",
       " 'conv3_3': <tf.Tensor 'BiasAdd_6:0' shape=(1, 128, 128, 256) dtype=float32>,\n",
       " 'conv3_4': <tf.Tensor 'BiasAdd_7:0' shape=(1, 128, 128, 256) dtype=float32>,\n",
       " 'conv4_1': <tf.Tensor 'BiasAdd_8:0' shape=(1, 64, 64, 512) dtype=float32>,\n",
       " 'conv4_2': <tf.Tensor 'BiasAdd_9:0' shape=(1, 64, 64, 512) dtype=float32>,\n",
       " 'conv4_3': <tf.Tensor 'BiasAdd_10:0' shape=(1, 64, 64, 512) dtype=float32>,\n",
       " 'conv4_4': <tf.Tensor 'BiasAdd_11:0' shape=(1, 64, 64, 512) dtype=float32>,\n",
       " 'conv5_1': <tf.Tensor 'BiasAdd_12:0' shape=(1, 32, 32, 512) dtype=float32>,\n",
       " 'conv5_2': <tf.Tensor 'BiasAdd_13:0' shape=(1, 32, 32, 512) dtype=float32>,\n",
       " 'conv5_3': <tf.Tensor 'BiasAdd_14:0' shape=(1, 32, 32, 512) dtype=float32>,\n",
       " 'conv5_4': <tf.Tensor 'BiasAdd_15:0' shape=(1, 32, 32, 512) dtype=float32>,\n",
       " 'pool1': <tf.Tensor 'MaxPool:0' shape=(1, 256, 256, 64) dtype=float32>,\n",
       " 'pool2': <tf.Tensor 'MaxPool_1:0' shape=(1, 128, 128, 128) dtype=float32>,\n",
       " 'pool3': <tf.Tensor 'MaxPool_2:0' shape=(1, 64, 64, 256) dtype=float32>,\n",
       " 'pool4': <tf.Tensor 'MaxPool_3:0' shape=(1, 32, 32, 512) dtype=float32>,\n",
       " 'relu1_1': <tf.Tensor 'Relu:0' shape=(1, 512, 512, 64) dtype=float32>,\n",
       " 'relu1_2': <tf.Tensor 'Relu_1:0' shape=(1, 512, 512, 64) dtype=float32>,\n",
       " 'relu2_1': <tf.Tensor 'Relu_2:0' shape=(1, 256, 256, 128) dtype=float32>,\n",
       " 'relu2_2': <tf.Tensor 'Relu_3:0' shape=(1, 256, 256, 128) dtype=float32>,\n",
       " 'relu3_1': <tf.Tensor 'Relu_4:0' shape=(1, 128, 128, 256) dtype=float32>,\n",
       " 'relu3_2': <tf.Tensor 'Relu_5:0' shape=(1, 128, 128, 256) dtype=float32>,\n",
       " 'relu3_3': <tf.Tensor 'Relu_6:0' shape=(1, 128, 128, 256) dtype=float32>,\n",
       " 'relu3_4': <tf.Tensor 'Relu_7:0' shape=(1, 128, 128, 256) dtype=float32>,\n",
       " 'relu4_1': <tf.Tensor 'Relu_8:0' shape=(1, 64, 64, 512) dtype=float32>,\n",
       " 'relu4_2': <tf.Tensor 'Relu_9:0' shape=(1, 64, 64, 512) dtype=float32>,\n",
       " 'relu4_3': <tf.Tensor 'Relu_10:0' shape=(1, 64, 64, 512) dtype=float32>,\n",
       " 'relu4_4': <tf.Tensor 'Relu_11:0' shape=(1, 64, 64, 512) dtype=float32>,\n",
       " 'relu5_1': <tf.Tensor 'Relu_12:0' shape=(1, 32, 32, 512) dtype=float32>,\n",
       " 'relu5_2': <tf.Tensor 'Relu_13:0' shape=(1, 32, 32, 512) dtype=float32>,\n",
       " 'relu5_3': <tf.Tensor 'Relu_14:0' shape=(1, 32, 32, 512) dtype=float32>,\n",
       " 'relu5_4': <tf.Tensor 'Relu_15:0' shape=(1, 32, 32, 512) dtype=float32>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_preloaded(img, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_31:0' shape=(1, 32, 32, 512) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu5_4=net_preloaded(img, weights)['relu5_4']\n",
    "    \n",
    "relu5_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'batchnorm/add_1:0' shape=(1, 4096) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape=int(np.prod(relu5_4.get_shape()[1:]))\n",
    "weight=tf.Variable(tf.truncated_normal([shape,4096],dtype=tf.float32,stddev=1e-1))\n",
    "bias=tf.Variable(tf.constant(1.0,shape=[4096],dtype=tf.float32))\n",
    "flat=tf.reshape(relu5_4,[-1,shape])\n",
    "fc6=tf.nn.bias_add(tf.matmul(flat,weight),bias)\n",
    "fc6=tf.nn.relu(fc6) \n",
    "fc6=batch_norm(fc6)\n",
    "fc6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'batchnorm_1/add_1:0' shape=(1, 1024) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight=tf.Variable(tf.truncated_normal([4096,1024],dtype=tf.float32,stddev=1e-1))\n",
    "bias=tf.Variable(tf.constant(1.0,shape=[1024],dtype=tf.float32))\t   \n",
    "fc7=tf.nn.bias_add(tf.matmul(fc6,weight),bias)\n",
    "fc7=tf.nn.relu(fc7) \n",
    "fc7=batch_norm(fc7) \n",
    "fc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'batchnorm_2/add_1:0' shape=(1, 256) dtype=float32>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight=tf.Variable(tf.truncated_normal([1024,256],dtype=tf.float32,stddev=1e-1))\n",
    "bias=tf.Variable(tf.constant(1.0,shape=[256],dtype=tf.float32))\t   \n",
    "fc8=tf.nn.bias_add(tf.matmul(fc7,weight),bias)\n",
    "fc8=tf.nn.relu(fc8) \n",
    "fc8=batch_norm(fc8) \n",
    "fc8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softmax:0' shape=(1, 2) dtype=float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight=tf.Variable(tf.truncated_normal([256,2],dtype=tf.float32,stddev=1e-1))\n",
    "bias=tf.Variable(tf.constant(1.0,shape=[2],dtype=tf.float32))\n",
    "softmax = tf.nn.bias_add(tf.matmul(fc8,weight),bias)   \n",
    "softmax = tf.nn.softmax(softmax)\n",
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"VGG19_LAYERS\"):\n",
    "    relu5_4=net_preloaded(input,weights)['relu5_4']\n",
    "\n",
    "with tf.variable_scope('FC_Softmax'):\n",
    "    #block6 : [batch, 8, 8, 512] => [batch, 4096]\n",
    "    with tf.variable_scope('FC6') as scope:\n",
    "        shape=int(np.prod(relu5_4.get_shape()[1:]))\n",
    "        weight=tf.Variable(tf.truncated_normal([shape,4096],dtype=tf.float32,stddev=1e-1))\n",
    "        bias=tf.Variable(tf.constant(1.0,shape=[4096],dtype=tf.float32))\n",
    "        flat=tf.reshape(relu5_4,[-1,shape])\n",
    "        fc6=tf.nn.bias_add(tf.matmul(flat,weight),bias)\n",
    "        fc6=tf.nn.relu(fc6) \n",
    "        fc6=batch_norm(fc6)\n",
    "    #block7 : [batch, 4096] => [batch, 1024]\n",
    "    with tf.variable_scope('FC7') as scope:\t\n",
    "        weight=tf.Variable(tf.truncated_normal([4096,1024],dtype=tf.float32,stddev=1e-1))\n",
    "        bias=tf.Variable(tf.constant(1.0,shape=[1024],dtype=tf.float32))\t   \n",
    "        fc7=tf.nn.bias_add(tf.matmul(fc6,weight),bias)\n",
    "        fc7=tf.nn.relu(fc7) \n",
    "        fc7=batch_norm(fc7) \n",
    "    #block8 : [batch, 1024] => [batch, 256]\n",
    "    with tf.variable_scope('FC8') as scope:\t\n",
    "        weight=tf.Variable(tf.truncated_normal([1024,256],dtype=tf.float32,stddev=1e-1))\n",
    "        bias=tf.Variable(tf.constant(1.0,shape=[256],dtype=tf.float32))\t   \n",
    "        fc8=tf.nn.bias_add(tf.matmul(fc7,weight),bias)\n",
    "        fc8=tf.nn.relu(fc8) \n",
    "        fc8=batch_norm(fc8) \n",
    "    #block8 : [batch, 256] => [batch, 2]\n",
    "    with tf.variable_scope('Softmax9') as scope:\t\n",
    "        weight=tf.Variable(tf.truncated_normal([256,2],dtype=tf.float32,stddev=1e-1))\n",
    "        bias=tf.Variable(tf.constant(1.0,shape=[2],dtype=tf.float32))\t\n",
    "        softmax = tf.add(tf.matmul(fc8,weights),biases)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
