{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import skimage.color\n",
    "from argparse import ArgumentParser\n",
    "import Generative_Network\n",
    "import Discriminative_Network\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINALPALETTE = 'uv_palette.npy'\n",
    "TRAININGDATAPATH = 'train_data.npy'\n",
    "VGG_PATH = 'imagenet-vgg-verydeep-19.mat'\n",
    "BATCHSIZE = 4\n",
    "ITERATIONS = 100000\n",
    "TRAININGRATIO = 10\n",
    "LEARNINGRATE = 1e-4\n",
    "\n",
    "def build_parser():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--palettepath',\n",
    "            dest='palettepath', help='load the original color palette',\n",
    "            metavar='ORIGINALPALETTE', default=ORIGINALPALETTE)\n",
    "    parser.add_argument('--trainingdatapath',\n",
    "            dest='trainingdatapath', help='training data in npy format',\n",
    "            metavar='TRAININGDATAPATH', default=TRAININGDATAPATH)\n",
    "    parser.add_argument('--vggpath',\n",
    "            dest='vggpath', help='load pre-trained VGG19 model',\n",
    "            metavar='VGG_PATH', default=VGG_PATH)\n",
    "    parser.add_argument('--iterations', type=int,\n",
    "            dest='iterations', help='iterations (default %(default)s)',\n",
    "            metavar='ITERATIONS', default=ITERATIONS)\n",
    "    parser.add_argument('--batchsize', type=int,\n",
    "            dest='batchsize', help='define the size of batch in training',\n",
    "            metavar='BATCHSIZE', default=BATCHSIZE)\n",
    "    parser.add_argument('--trainingratio', type=int,\n",
    "            dest='trainingratio', help='define the iteration ratio between DN and GN',\n",
    "            metavar='TRAININGRATIO', default=TRAININGRATIO)\n",
    "    parser.add_argument('--learningrate', type=int,\n",
    "            dest='learningrate', help='define the learning rate of Adamoptimizaer',\n",
    "            metavar='LEARNINGRATE', default=LEARNINGRATE) \n",
    "    \n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g_network(image, rgb_palette, reuse=False):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    fake_image = Generative_Network.net(image, rgb_palette)\n",
    "    return fake_image\n",
    "\n",
    "def d_network(image, weights, reuse = False):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()    \n",
    "    prob, logits = Discriminative_Network.discriminator(image, weights)   \n",
    "    return prob, logits\n",
    "\n",
    "def next_batch(num, data):\n",
    "    '''\n",
    "    Return a total of `num` random samples\n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle_color = np.array([rgb2yuv(data[i]) for i in idx]) ### RGB Space\n",
    "    data_shuffle_gray = np.array([np.reshape(rgb2yuv(data[i])[:,:,0], [128, 128, 1]) for i in idx]) ### Gray Space\n",
    "    return data_shuffle_color, data_shuffle_gray\n",
    "\n",
    "def rgb2yuv(image):\n",
    "    yuv_color = skimage.color.rgb2yuv(image)\n",
    "    return yuv_color\n",
    "\n",
    "\n",
    "def yuv2rgb(image):\n",
    "    rgb_color = skimage.color.yuv2rgb(image)\n",
    "    return rgb_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = build_parser()\n",
    "    options = parser.parse_args()\n",
    "    \n",
    "    #Palette loading\n",
    "    palettepath = options.palettepath\n",
    "    orig_palette = np.load(palettepath)\n",
    "    \n",
    "    #Training Data Preparation\n",
    "    training_path = options.trainingdatapath\n",
    "    training_data = np.load(training_path)\n",
    "    imagelist = []\n",
    "    for i in range(295):\n",
    "        imagelist.append(np.squeeze(training_data[i,:,:,:]))\n",
    "    \n",
    "    #VGG Model Loading\n",
    "    net_path = options.vggpath\n",
    "    weights, mean_pixel = Discriminative_Network.load_net(net_path)\n",
    "    \n",
    "    learningrate = options.learningrate\n",
    "    batch_size = options.batchsize\n",
    "    iterations = options.iterations\n",
    "    trainingratio = options.trainingratio\n",
    "    \n",
    "    print('Data loading completed')\n",
    "\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "\n",
    "        X = tf.placeholder(tf.float32, [batch_size, 128, 128, 1])\n",
    "        Y = tf.placeholder(tf.float32, [batch_size, 128, 128, 3])\n",
    "\n",
    "        with tf.name_scope('generating'):\n",
    "            G_sample = g_network(X, orig_palette)\n",
    "\n",
    "        with tf.name_scope('discriminating'):\n",
    "            mean_tensor = tf.cast(np.reshape(mean_pixel, [1,1,1,3]), tf.float32)\n",
    "            #Y_ = Y - mean_tensor\n",
    "            #G_sample_ = G_sample - mean_tensor       \n",
    "            D_real, D_logit_real = d_network(Y, weights) \n",
    "            D_fake, D_logit_fake = d_network(G_sample, weights)\n",
    "\n",
    "        with tf.name_scope('D_loss'):\n",
    "            D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
    "            D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
    "            D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "        with tf.name_scope('G_loss'):\n",
    "            G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))\n",
    "\n",
    "        tvar = tf.trainable_variables()\n",
    "        dvar = [var for var in tvar if 'discriminator' in var.name] # Find variable in DN\n",
    "        gvar = [var for var in tvar if 'generator' in var.name] # Find variable in GB\n",
    "\n",
    "        with tf.name_scope('train'):\n",
    "            d_train = tf.train.AdamOptimizer(learningrate).minimize(D_loss, var_list=dvar)\n",
    "            g_train = tf.train.AdamOptimizer(learningrate).minimize(G_loss, var_list=gvar)\n",
    "\n",
    "        print('Graph establised')\n",
    "\n",
    "        \n",
    "    with tf.Session(graph = g) as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        for i in range(iterations): # Train ratio: DN/GN = 100/1\n",
    "            print('Training Step:' + str(i+1))\n",
    "            \n",
    "            batch_img_color, batch_img_gray = next_batch(batch_size, imagelist)\n",
    "\n",
    "            if i % trainingratio == 0:\n",
    "                _, G_loss_curr, samples = sess.run([g_train, G_loss, G_sample], feed_dict={X:batch_img_gray, Y: batch_img_color})\n",
    "                if not os.path.isdir('tmp_output'):\n",
    "                    os.mkdir('tmp_output')                    \n",
    "                for index in range(batch_size):\n",
    "                    tmp_name = str(index)\n",
    "                    tmp_img = yuv2rgb(np.squeeze(samples[index,:,:,:]))\n",
    "                    scipy.misc.imsave('tmp_output/iteration_' + str(i) +'_' + tmp_name +'.jpg', tmp_img)\n",
    "                \n",
    "            _, D_loss_curr = sess.run([d_train, D_loss], feed_dict={X:batch_img_gray, Y: batch_img_color})\n",
    "        \n",
    "\n",
    "            if i % trainingratio == 0:\n",
    "                print(D_loss_curr, G_loss_curr)      \n",
    "              \n",
    "        save_path = saver.save(sess, \"/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading completed\n"
     ]
    }
   ],
   "source": [
    "palettepath = ORIGINALPALETTE\n",
    "orig_palette = np.load(palettepath)\n",
    "\n",
    "#Training Data Preparation\n",
    "training_path = TRAININGDATAPATH\n",
    "training_data = np.load(training_path)\n",
    "imagelist = []\n",
    "for i in range(295):\n",
    "    imagelist.append(np.squeeze(training_data[i,:,:,:]))\n",
    "    \n",
    "#VGG Model Loading\n",
    "net_path = VGG_PATH\n",
    "#weights, mean_pixel = Discriminative_Network.load_net(net_path)\n",
    "\n",
    "learningrate = LEARNINGRATE\n",
    "batch_size = BATCHSIZE\n",
    "iterations = ITERATIONS\n",
    "trainingratio = TRAININGRATIO\n",
    "gn_iterations = iterations / trainingratio\n",
    "\n",
    "print('Data loading completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rgb2lab(image):\n",
    "    '''\n",
    "    L range: 0 ~ 100\n",
    "    a range: -128 ~ 127\n",
    "    b range: -128 ~ 127\n",
    "    \n",
    "    '''\n",
    "    lab_color = skimage.color.rgb2lab(image)\n",
    "    return lab_color\n",
    "\n",
    "def lab2rgb(image):\n",
    "    rgb_color = skimage.color.lab2rgb(image)\n",
    "    return rgb_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'HSVToRGB:0' shape=(4, 128, 128, 3) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = tf.constant(1, dtype = tf.float32, shape = [4,128,128,1])\n",
    "fake = g_network(image, orig_palette, reuse=False)\n",
    "fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sample = fake.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
