{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import datetime\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.color\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "LAB -> 256 LAB Color \n",
    "\n",
    "> bw_conv1_1(conv) > relu1_1 > conv1_2(Stride:1) > relu1_2 > conv1_2norm\n",
    "===\n",
    "> conv2_1 > relu2_1 > conv2_2 (Stride:2) > relu2_2 > conv2_2norm\n",
    "===\n",
    "> conv3_1 > relu3_1 > conv3_2 > relu3_2 > conv3_3 (Stride:2)> relu3_3 > conv3_3norm\n",
    "===\n",
    "conv4_1 (Stride:1,pad:1 dilation: 1)> relu4_1 > conv4_2(same) > relu4_2 > conv4_3(same) > relu4_3 > conv4_3_norm\n",
    "===\n",
    "conv5_1(Stride:1,pad:2 dilation: 2) > relu5_1 > conv5_2(same) > relu5_2 > conv5_3 > relu5_3 > conv5_3_norm\n",
    "===\n",
    "conv6_1 (Stride:1,pad:2 dilation: 2)> relu6_1 > conv6_2(same) > relu6_2 > conv6_3(same) > relu6_3 > conv6_3_norm\n",
    "===\n",
    "conv7_1(Stride:1,pad:1 dilation: 1) > relu7_1 > conv7_2 > relu7_2 > conv7_3 > relu7_3 > conv7_3_norm\n",
    "===\n",
    "conv8_1(kernal:4 stride:2 pad:1 dilation:1) > relu8_1 > conv8_2(kernal:3 stride:1) > relu8_2 > conv8_3 > relu8_3 \n",
    "\n",
    "Testing Result：\n",
    "\n",
    "(1) s>1，即卷积的同时做了downsampling，卷积后图像尺寸减小；\n",
    "(2) s=1，普通的步长为1的卷积，比如在tensorflow中设置padding=SAME的话，卷积的图像输入和输出有相同的尺寸大小；\n",
    "(3) 0<s<1，fractionally strided convolution，相当于对图像做upsampling。比如s=0.5时，意味着在图像每个像素之间padding一个空白的像素后，\n",
    "stride改为1做卷积，得到的feature map尺寸增大一倍。\n",
    "\n",
    "'''\n",
    "print('Start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net(image):  ### 输入的图像不用normalization [batch, height = 256, width = 256, channel = 3]\n",
    "    normalization = batch_norm(image, train=True)\n",
    "    conv1_1_relu = conv_layer(normalization, 64, 3, 1, relu=True) #[batch, height = 256, width = 256, channel = 64]\n",
    "    conv1_2_relu = conv_layer(conv1_1_relu, 64, 3, 1, relu=True)\n",
    "    conv1_2norm = batch_norm(conv1_2_relu, train=True)\n",
    "\n",
    "    conv2_1_relu = conv_layer(conv1_2norm, 128, 3, 1, relu=True)\n",
    "    conv2_2_relu = conv_layer(conv1_1_relu, 128, 3, 2, relu=True) # \n",
    "    conv2_2norm = batch_norm(conv2_2_relu, train=True)\n",
    "\n",
    "\n",
    "    conv3_1_relu = conv_layer(conv2_2norm, 256, 3, 1, relu=True)\n",
    "    conv3_2_relu = conv_layer(conv3_1_relu, 256, 3, 1, relu=True)\n",
    "    conv3_3_relu = conv_layer(conv3_2_relu, 256, 3, 2, relu=True)\n",
    "    conv3_3norm = batch_norm(conv3_3_relu, train=True)\n",
    "    '''\n",
    "    conv4_1 (Stride:1,pad:1 dilation: 1)> relu4_1 > conv4_2(same) > relu4_2 > conv4_3(same) > relu4_3 > conv4_3_norm\n",
    "\n",
    "    tf.nn.atrous_conv2d(net, weights_init, rate, 'SAME')\n",
    "    conv_layer_dila(net, num_filters, filter_size, rate, relu=True)\n",
    "    '''\n",
    "    conv4_1_relu = conv_layer(conv3_3norm, 512, 3, 2, relu=True)\n",
    "    conv4_2_relu = conv_layer_dila(conv4_1_relu, 512, 3, 1, relu=True)\n",
    "    conv4_3_relu = conv_layer_dila(conv4_2_relu, 512, 3, 1, relu=True)\n",
    "    conv4_3norm = batch_norm(conv4_3_relu, train=True)\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    conv8_1(256, kernal:4 stride:2 pad:1 dilation:1) > relu8_1 > conv8_2(kernal:3 stride:1) > relu8_2 > conv8_3\n",
    "\n",
    "    '''\n",
    "    conv8_1_relu = conv_tranpose_layer(conv4_3norm, 256, 4, 2)\n",
    "    conv8_2_relu = conv_layer(conv8_1_relu, 256, 3, 1, relu=True)\n",
    "    conv8_3_relu = conv_layer(conv8_2_relu, 256, 3, 1, relu=True)\n",
    "    \n",
    "    \n",
    "    conv9_1 = conv_layer(conv8_3_relu, 313, 3, 1, relu=True)\n",
    "    conv9_2 = conv_layer(conv9_1, 313, 3, 1, relu=True)\n",
    "    #conv9_3 = conv_layer(conv9_2, 32, 3, 2, relu=True)\n",
    "    #conv9_4 = conv_layer(conv9_3, 3, 3, 1, relu=True)\n",
    "    \n",
    "\n",
    "    return conv9_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearest_search(image, palette):\n",
    "    '''\n",
    "    Palette shape: (16, 16, 3)\n",
    "    \n",
    "    '''\n",
    "    img_shape = image.shape\n",
    "    height = img_shape[0] \n",
    "    width = img_shape[1] \n",
    "    new_img = np.zeros(img_shape)\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            index = find_min_idx(np.sum((palette - image[i, j, :])**2,2)) ### Bugs\n",
    "            new_img[i, j, :] = palette[index[0], index[1], :]\n",
    "            \n",
    "    return new_img\n",
    "            \n",
    "\n",
    "def find_min_idx(x):\n",
    "    k = x.argmin()\n",
    "    ncol = x.shape[1]\n",
    "    return np.int(k/ncol), k%ncol\n",
    "\n",
    "\n",
    "def get_img(img_path):\n",
    "    img = scipy.misc.imread(img_path, mode = 'RGB')\n",
    "    return img\n",
    "\n",
    "def rgb2lab(image):\n",
    "    '''\n",
    "    L range: 0 ~ 100\n",
    "    a range: -128 ~ 127\n",
    "    b range: -128 ~ 127\n",
    "    \n",
    "    '''\n",
    "    lab_color = skimage.color.rgb2lab(image)\n",
    "    return lab_color\n",
    "\n",
    "\n",
    "def lab2rgb(image):\n",
    "    rgb_color = skimage.color.lab2rgb(image)\n",
    "    return rgb_color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_init_vars(net, out_channels, filter_size, transpose=False):\n",
    "    '''\n",
    "    \n",
    "    According to the previous output, intialize the weight matrix.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    _, rows, cols, in_channels = [i.value for i in net.get_shape()] ### Obtain in_channels\n",
    "    \n",
    "    if not transpose:\n",
    "        weights_shape = [filter_size, filter_size, in_channels, out_channels]\n",
    "    else:\n",
    "        weights_shape = [filter_size, filter_size, out_channels, in_channels]\n",
    "    \n",
    "    # weights shape = [Kernal size, kernal size, output kernal, input kernal]\n",
    "\n",
    "    weights_init = tf.Variable(tf.truncated_normal(weights_shape, stddev = 0.1, seed=1), dtype=tf.float32)\n",
    "    \n",
    "    return weights_init\n",
    "\n",
    "\n",
    "\n",
    "def batch_norm(net, train=True):\n",
    "    '''\n",
    "    \n",
    "    Apply Batch Normalization Function\n",
    "    \n",
    "    BN: Forward norm and then inverse norm.\n",
    "    \n",
    "    '''\n",
    "    batch, rows, cols, channels = [i.value for i in net.get_shape()]### Shape Meaning: [batchsize, height, width, kernels]\n",
    "    var_shape = [channels]\n",
    "    mu, sigma_sq = tf.nn.moments(net, [1,2], keep_dims=True) ### Calculate the mean and variance of x.Output: One-dimension\n",
    "    shift = tf.Variable(tf.zeros(var_shape)) ### Inverse Norm\n",
    "    scale = tf.Variable(tf.ones(var_shape)) ### Inverse Norm\n",
    "    epsilon = 1e-3\n",
    "    normalized = (net-mu)/(sigma_sq + epsilon)**(.5)\n",
    "    return scale * normalized + shift ### Applied Batch Normalization\n",
    "\n",
    "\n",
    "def conv_layer(net, num_filters, filter_size, strides, relu=True):\n",
    "    '''\n",
    "    \n",
    "    Apply convolution operation\n",
    "    \n",
    "    '''\n",
    "    weights_init = conv_init_vars(net, num_filters, filter_size)\n",
    "    strides_shape = [1, strides, strides, 1]                \n",
    "    net = tf.nn.conv2d(net, weights_init, strides_shape, padding='SAME')\n",
    "    \n",
    "    if relu:\n",
    "        net = tf.nn.relu(net)   \n",
    "    \n",
    "    return net        \n",
    "\n",
    "def conv_layer_dila(net, num_filters, filter_size, rate, relu=True):\n",
    "    '''\n",
    "    \n",
    "    Apply dilation convolution operation\n",
    "    \n",
    "    '''\n",
    "    weights_init = conv_init_vars(net, num_filters, filter_size)\n",
    "    #strides_shape = [1, strides, strides, 1]\n",
    "    \n",
    "    net = tf.nn.atrous_conv2d(net, weights_init, rate, 'SAME') # Dialation Convolution\n",
    "                 \n",
    "    \n",
    "    if relu:\n",
    "        net = tf.nn.relu(net)   \n",
    "    \n",
    "    return net   \n",
    "\n",
    "def conv_tranpose_layer(net, num_filters, filter_size, strides):\n",
    "    weights_init = conv_init_vars(net, num_filters, filter_size, transpose=True)\n",
    "\n",
    "    batch_size, rows, cols, in_channels = [i.value for i in net.get_shape()]\n",
    "    new_rows, new_cols = int(rows * strides), int(cols * strides)\n",
    "    # new_shape = #tf.pack([tf.shape(net)[0], new_rows, new_cols, num_filters])\n",
    "    new_shape = [batch_size, new_rows, new_cols, num_filters]  \n",
    "    tf_shape = tf.stack(new_shape)   \n",
    "    strides_shape = [1,strides,strides,1]\n",
    "    net = tf.nn.conv2d_transpose(net, weights_init, tf_shape, strides_shape, padding='SAME')\n",
    "    return tf.nn.relu(net)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Img loading\n",
    "\n",
    "'''\n",
    "img_path = 'C:\\\\Users\\\\Orion_Peng\\\\Pictures\\\\Saved Pictures\\\\dog.jpg'\n",
    "\n",
    "img = get_img(img_path)\n",
    "\n",
    "img_resize = scipy.misc.imresize(img, (256, 256)) #Input image\n",
    "\n",
    "img_resize_lab = rgb2lab(img_resize)\n",
    "\n",
    "input_img = np.array([img_resize_lab]) ### Batch \n",
    "\n",
    "input_img = tf.cast(input_img, tf.float32) ### Transform into tensor\n",
    "\n",
    "palette = net(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Method 1: Use two for loops to achieve NNR\n",
    "'''\n",
    "\n",
    "\n",
    "palette = tf.reshape(palette, [256, 1, 3])\n",
    "\n",
    "img_resize_2 = scipy.misc.imresize(img, (32, 32))\n",
    "\n",
    "resize_float32 = img_resize_2.astype(np.float32)\n",
    "\n",
    "new_img = tf.Variable(resize_float32, tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(32):\n",
    "        for j in range(32):\n",
    "            loss = tf.reduce_sum((palette - new_img [i, j, :])**2, 2)\n",
    "\n",
    "            loss_int = tf.cast(loss, tf.int32)\n",
    "\n",
    "            loss_value = tf.cast(tf.argmin(loss_int), tf.int32)\n",
    "            \n",
    "            print(loss_value.eval())\n",
    "\n",
    "            result = tf.assign(new_img[i, j, :], palette[loss_value[0], 0, :])\n",
    "        \n",
    "            best = result.eval()\n",
    "\n",
    "\n",
    "\n",
    "print('Two for loops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(resize_2)\n",
    "plt.figure()\n",
    "plt.imshow(best.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_float32 = resize_2.astype(np.float32)\n",
    "resize_float32 = tf.cast(resize_float32, tf.float32)\n",
    "resize_float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "Method 2: Produce index map\n",
    "\n",
    "'''\n",
    "palette  = tf.reshape(palette, [256, 1, 3]) # \n",
    "\n",
    "### How to define the loss ??\n",
    "img_resize_2 = scipy.misc.imresize(img, (256, 256))\n",
    "\n",
    "resize_float32 = img_resize_2.astype(np.float32)\n",
    "\n",
    "resize_float32 = tf.cast(resize_float32, tf.float32)\n",
    "\n",
    "loss = tf.reshape(tf.reduce_sum((palette[0, 0, :] - resize_float32)**2, 2), [256, 256, 1]) \n",
    "\n",
    "for i in range(1,256):\n",
    "    loss_ = tf.reshape(tf.reduce_sum((palette[i, 0, :] - resize_float32)**2, 2), [256, 256, 1]) \n",
    "\n",
    "    loss = tf.concat([loss, loss_], axis = 2)\n",
    "    \n",
    "index = tf.argmin(loss, axis = 2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output_palette = palette.eval()\n",
    "    output = index.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Method 3: Interpolation\n",
    "\n",
    "'''\n",
    "\n",
    "start_time = datetime.datetime.now() \n",
    "\n",
    "img_path = 'C:\\\\Users\\\\Orion_Peng\\\\Pictures\\\\Saved Pictures\\\\dog.jpg'\n",
    "\n",
    "img = get_img(img_path)\n",
    "\n",
    "img_resize = scipy.misc.imresize(img, (256, 256)) #Input image\n",
    "\n",
    "img_resize_lab = rgb2lab(img_resize)\n",
    "\n",
    "input_img = np.array([img_resize_lab]) ### Batch \n",
    "\n",
    "input_img = tf.cast(input_img, tf.float32) ### Transform into tensor\n",
    "\n",
    "relu9_2 = net(input_img)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output = relu9_2.eval()\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "print((end_time - start_time).seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class8_313_rh = tf.nn.softmax(relu9_2)\n",
    "class8_313_rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quantized_ab = np.load('./pts_in_hull.npy')\n",
    "filter_8_313 = tf.Variable(np.transpose(quantized_ab, [1,0]), dtype=tf.float32, name='filter_8_313')\n",
    "filter_8_313 = tf.reshape(filter_8_313, [1, 1, 313, 2])\n",
    "\n",
    "class8_ab = tf.nn.conv2d(class8_313_rh, filter_8_313, strides=[1,1,1,1], padding='VALID')\n",
    "\n",
    "result = tf.image.resize_images(class8_ab, (256, 256), method = 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output = result.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_output = np.reshape(output, [256, 256, 2])\n",
    "\n",
    "lumi = img_resize_lab[:,:,0]\n",
    "lumi_ = np.reshape(lumi, [256, 256, 1])\n",
    "output_lab = np.concatenate((lumi_,reshape_output), axis = 2)\n",
    "final_img = lab2rgb(output_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_lab[0, 0, :])\n",
    "print(final_img[0, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Idea: Return the index value and the x, y position.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_palette = output_palette.astype(np.uint8)\n",
    "\n",
    "output_palette = palette.eval()\n",
    "output = index.eval()\n",
    "\n",
    "\n",
    "new_img = np.zeros([64, 64, 3])\n",
    "for i in range(64):\n",
    "    for j in range(64):\n",
    "        new_img[i, j, :] = final_palette[output[i,j], 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(new_img.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
