{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "VGG19_LAYERS=(\n",
    "    'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
    "\n",
    "    'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    "\n",
    "    'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
    "    'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    "\n",
    "    'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
    "    'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    "\n",
    "    'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
    "    'relu5_3', 'conv5_4', 'relu5_4'\n",
    ")\n",
    "\n",
    "def load_net(data_path):\n",
    "    data = scipy.io.loadmat(data_path)\n",
    "    weights = data['layers'][0]\n",
    "    #use the original code in vgg19.py\n",
    "    mean = data['normalization'][0][0][0]\n",
    "    mean_pixel = np.mean(mean, axis=(0, 1))\n",
    "    return weights, mean_pixel \n",
    "\n",
    "def _conv_layer(input, weights, bias):\n",
    "    conv = tf.nn.conv2d(input, tf.constant(weights), strides=(1, 1, 1, 1),\n",
    "            padding='SAME')\n",
    "    return tf.nn.bias_add(conv, bias)\n",
    "\n",
    "def _pool_layer(input):\n",
    "    return tf.nn.max_pool(input, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1),\n",
    "            padding='SAME')\n",
    "\n",
    "def preprocess(image, mean_pixel):\n",
    "    return image - mean_pixel\n",
    "\n",
    "def unprocess(image, mean_pixel):\n",
    "    return image + mean_pixel\n",
    "\n",
    "def net_preloaded(input_image, weights):\n",
    "    net = {}\n",
    "    current = input_image\n",
    "\n",
    "    for i, name in enumerate(VGG19_LAYERS):\n",
    "        kind = name[:4]\n",
    "        if kind == 'conv':\n",
    "            #use the original code in vgg19.py\n",
    "            kernels, bias = weights[i][0][0][0][0]\n",
    "            # tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "            kernels = np.transpose(kernels, (1, 0, 2, 3))\n",
    "            bias = bias.reshape(-1)\n",
    "\n",
    "            current = _conv_layer(current, kernels, bias)\n",
    "        elif kind == 'relu':\n",
    "            current = tf.nn.relu(current)\n",
    "        elif kind == 'pool':\n",
    "            current = _pool_layer(current)\n",
    "        net[name] = current\n",
    "\n",
    "    assert len(net) == len(VGG19_LAYERS)\n",
    "    return net\n",
    "\n",
    "def batch_norm(input):\n",
    "    epsilon = 1e-3\n",
    "    batch_mean,batch_var=tf.nn.moments(input,[0])\n",
    "    normalized=tf.nn.batch_normalization(input,mean=batch_mean,variance=batch_var,offset=None,scale=None,variance_epsilon=epsilon)\n",
    "    return normalized\n",
    "\n",
    "def discrimator(input_image,netpath):\n",
    "    weights, mean_pixel = load_net(netpath)\n",
    "    img = preprocess(input_image, mean_pixel)\n",
    "    img = np.array([img]).astype(np.float32)\n",
    "    \n",
    "    with tf.variable_scope(\"VGG19_LAYERS\"):\n",
    "        relu5_4 = net_preloaded(img, weights)['relu5_4']\n",
    "\n",
    "    with tf.variable_scope('FC_Softmax'):\n",
    "    #block6 : [batch, 16, 16, 512] => [batch, 4096]\n",
    "    #if i check the shape of relu5_4, the result must be [batch, 16, 16, 512] not [batch, 8, 8, 512]\n",
    "        with tf.variable_scope('FC6') as scope:\n",
    "            shape=int(np.prod(relu5_4.get_shape()[1:]))\n",
    "            weight=tf.Variable(tf.truncated_normal([shape,4096],dtype=tf.float32,stddev=1e-1))\n",
    "            bias=tf.Variable(tf.constant(1.0,shape=[4096],dtype=tf.float32))\n",
    "            flat=tf.reshape(relu5_4,[-1,shape])\n",
    "            fc6=tf.nn.bias_add(tf.matmul(flat,weight),bias)\n",
    "            fc6=tf.nn.relu(fc6) \n",
    "            fc6=batch_norm(fc6)\n",
    "        #block7 : [batch, 4096] => [batch, 1024]\n",
    "        with tf.variable_scope('FC7') as scope:\t\n",
    "            weight=tf.Variable(tf.truncated_normal([4096,4096],dtype=tf.float32,stddev=1e-1))\n",
    "            bias=tf.Variable(tf.constant(1.0,shape=[4096],dtype=tf.float32))\t   \n",
    "            fc7=tf.nn.bias_add(tf.matmul(fc6,weight),bias)\n",
    "            fc7=tf.nn.relu(fc7) \n",
    "            fc7=batch_norm(fc7)\n",
    "        #block8 : [batch, 1024] => [batch, 256]\n",
    "        with tf.variable_scope('FC8') as scope:\t\n",
    "            weight=tf.Variable(tf.truncated_normal([4096,256],dtype=tf.float32,stddev=1e-1))\n",
    "            bias=tf.Variable(tf.constant(1.0,shape=[256],dtype=tf.float32))\t   \n",
    "            fc8=tf.nn.bias_add(tf.matmul(fc7,weight),bias)\n",
    "            fc8=tf.nn.relu(fc8) \n",
    "            fc8=batch_norm(fc8)\n",
    "        #block8 : [batch, 256] => [batch, 2]\n",
    "        with tf.variable_scope('Softmax9') as scope:\n",
    "            weight=tf.Variable(tf.truncated_normal([256,2],dtype=tf.float32,stddev=1e-1))\n",
    "            bias=tf.Variable(tf.constant(1.0,shape=[2],dtype=tf.float32))\n",
    "            softmax = tf.nn.bias_add(tf.matmul(fc8,weight),bias)   \n",
    "            softmax = tf.nn.softmax(softmax)  \n",
    "\n",
    "    return softmax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_path = 'D:\\\\PythonScript\\\\Dissertation\\\\Gatys Implemention\\\\Style_transfer_Saliency_loss\\\\imagenet-vgg-verydeep-19.mat'\n",
    "img_path = 'C:\\\\Users\\\\Orion_Peng\\\\Pictures\\\\animal_1_resize.jpg'\n",
    "\n",
    "img = scipy.misc.imread(img_path)\n",
    "resize = scipy.misc.imresize(img, (256, 256))\n",
    "\n",
    "b = discrimator(resize, net_path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    output = b.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    #net and image both in current dir\n",
    "\n",
    "\n",
    "    img = scipy.misc.imread(img_path)\n",
    "    resize = scipy.misc.imresize(img, (256, 256))\n",
    "    img=resize\n",
    "\n",
    "    softmax = discrimator(img,net_path)\n",
    "    softmax\n",
    "    softmax.shape\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    #be careful, it need lots of memory....\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    softmax.eval()\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
